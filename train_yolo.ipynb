{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f774c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script train YOLOv8n ƒë·ªÉ nh·∫≠n di·ªán bi·ªÉn b√°o giao th√¥ng\n",
    "T·ªëi ∆∞u ƒë·ªÉ deploy tr√™n Raspberry Pi 5 (train tr√™n GPU m·∫°nh)\n",
    "\"\"\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "504f6247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíª KI·ªÇM TRA PH·∫¶N C·ª®NG TRAINING\n",
      "==================================================\n",
      "CUDA available: False\n",
      "‚ö†Ô∏è  Training tr√™n CPU (s·∫Ω ch·∫≠m h∆°n)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüíª KI·ªÇM TRA PH·∫¶N C·ª®NG TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name())\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"‚úÖ S·ª≠ d·ª•ng GPU ƒë·ªÉ training nhanh h∆°n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Training tr√™n CPU (s·∫Ω ch·∫≠m h∆°n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o model YOLOv8n v·ªõi pretrained weights\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# C·∫•u h√¨nh c√°c hyperparameters\n",
    "train_params = {\n",
    "    'data': \"dataset.yaml\",          # File c·∫•u h√¨nh dataset\n",
    "    'epochs': 30,                    # S·ªë epoch (250 cho l·∫ßn train cu·ªëi)\n",
    "    'patience': 15,                  # Early stopping (30 cho l·∫ßn train cu·ªëi)\n",
    "    'batch': -1,                     # Auto batch size\n",
    "    'workers': 8,                    # S·ªë worker\n",
    "    'name': 'fpt_hackathon',         # T√™n experiment\n",
    "    'exist_ok': True,                # Ghi ƒë√® n·∫øu ƒë√£ t·ªìn t·∫°i\n",
    "    'cache': True,                   # Cache d·ªØ li·ªáu\n",
    "    'cos_lr': True,                  # S·ª≠ d·ª•ng cosine LR scheduler\n",
    "    'close_mosaic': 10,              # ƒê√≥ng mosaic sau 10 epoch\n",
    "}\n",
    "\n",
    "print(\"üìä Training parameters:\")\n",
    "for k, v in train_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2068162",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== üîß B·∫ÆT ƒê·∫¶U TRAINING ===\")\n",
    "results = model.train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = f\"{results.save_dir}/weights/best.pt\"\n",
    "print(f\"‚úÖ Best model saved at: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c69fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== üì§ B·∫ÆT ƒê·∫¶U EXPORT ===\")\n",
    "try:\n",
    "    export_path = model.export(format='ncnn')\n",
    "    print(f\"‚úÖ Export th√†nh c√¥ng: {export_path}\")\n",
    "except Exception as e:\n",
    "    export_path = None\n",
    "    print(f\"‚ùå Export th·∫•t b·∫°i: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edf540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y ƒë∆∞·ªùng d·∫´n ƒë·∫øn best model\n",
    "best_model_path = os.path.join('runs', 'detect', 'fpt_hackathon', 'weights', 'best.pt')\n",
    "\n",
    "if export_path and os.path.exists(best_model_path):\n",
    "    print(\"\\nüéâ HO√ÄN T·∫§T QU√Å TR√åNH TRAIN & EXPORT!\")\n",
    "    print(f\"üìÅ PyTorch model: {best_model_path}\")\n",
    "    print(f\"üì± NCNN model directory: {export_path}\")\n",
    "    size_mb = os.path.getsize(best_model_path) / (1024*1024)\n",
    "    print(f\"üìä K√≠ch th∆∞·ªõc model (PyTorch): {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Ki·ªÉm tra k√≠ch th∆∞·ªõc NCNN model files\n",
    "    ncnn_param_path = os.path.join(export_path, 'model.ncnn.param')\n",
    "    ncnn_bin_path = os.path.join(export_path, 'model.ncnn.bin')\n",
    "    \n",
    "    if os.path.exists(ncnn_param_path) and os.path.exists(ncnn_bin_path):\n",
    "        param_size_mb = os.path.getsize(ncnn_param_path) / (1024*1024)\n",
    "        bin_size_mb = os.path.getsize(ncnn_bin_path) / (1024*1024)\n",
    "        total_ncnn_size = param_size_mb + bin_size_mb\n",
    "        print(f\"üìä K√≠ch th∆∞·ªõc NCNN param: {param_size_mb:.2f} MB\")\n",
    "        print(f\"üìä K√≠ch th∆∞·ªõc NCNN bin: {bin_size_mb:.2f} MB\")\n",
    "        print(f\"üìä T·ªïng k√≠ch th∆∞·ªõc NCNN: {total_ncnn_size:.2f} MB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file NCNN model\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng export ƒë∆∞·ª£c model sang NCNN ho·∫∑c kh√¥ng t√¨m th·∫•y best model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
